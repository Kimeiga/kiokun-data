name: Build Dictionaries (Matrix)

on:
  push:
    branches: [main]
  workflow_dispatch: # Allow manual triggering
  schedule:
    - cron: "0 0 1 * *" # Run monthly

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        shard-type: [non-han, han-1char, han-2char, han-3plus]
      fail-fast: false # Continue other shards even if one fails
    
    steps:
      - name: Checkout source code
        uses: actions/checkout@v3
        with:
          lfs: true

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable

      - name: Build Rust project
        run: |
          echo "üî® Building Rust project..."
          cargo build --release

      - name: Run dictionary build for ${{ matrix.shard-type }}
        run: |
          echo "üéØ Building dictionary shard: ${{ matrix.shard-type }}..."
          cargo run --release --bin merge_dictionaries -- --individual-files --optimize --mode ${{ matrix.shard-type }}

      - name: Verify output
        run: |
          SHARD_DIR="output_${{ matrix.shard-type }}"
          if [ ! -d "$SHARD_DIR" ]; then
            echo "‚ùå Error: Output directory $SHARD_DIR not found!"
            exit 1
          fi
          
          FILE_COUNT=$(find "$SHARD_DIR" -name "*.json" | wc -l)
          echo "‚úÖ Generated $FILE_COUNT JSON files in $SHARD_DIR"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "‚ùå Error: No JSON files generated!"
            exit 1
          fi

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install --update
          aws --version

      - name: Upload to Cloudflare R2 using S3 API
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          SHARD_DIR="output_${{ matrix.shard-type }}"
          BUCKET_NAME="kiokun-dict"

          echo "‚òÅÔ∏è Uploading to Cloudflare R2..."
          echo "   Bucket: $BUCKET_NAME"
          echo "   Shard: ${{ matrix.shard-type }}"

          # Count files before upload
          FILE_COUNT=$(find "$SHARD_DIR" -name "*.json" | wc -l)
          TOTAL_SIZE=$(du -sh "$SHARD_DIR" | cut -f1)

          echo "   Files: $FILE_COUNT"
          echo "   Size: $TOTAL_SIZE"

          # R2 endpoint URL (S3-compatible)
          ENDPOINT_URL="https://${CLOUDFLARE_ACCOUNT_ID}.r2.cloudflarestorage.com"

          echo "üì§ Starting batch upload using AWS S3 sync..."

          # Use AWS S3 sync for fast batch upload
          # This is MUCH faster than uploading files one-by-one
          aws s3 sync "$SHARD_DIR" "s3://$BUCKET_NAME/${{ matrix.shard-type }}" \
            --endpoint-url "$ENDPOINT_URL" \
            --no-progress \
            --only-show-errors

          echo "‚úÖ Upload complete!"
          echo "   Files are now available at: https://dict.kiokun.dev/${{ matrix.shard-type }}/{word}.json"

      - name: Summary
        if: always()
        run: |
          echo "üìä Build Summary for ${{ matrix.shard-type }}"
          echo "================================"
          SHARD_DIR="output_${{ matrix.shard-type }}"
          if [ -d "$SHARD_DIR" ]; then
            FILE_COUNT=$(find "$SHARD_DIR" -name "*.json" | wc -l)
            TOTAL_SIZE=$(du -sh "$SHARD_DIR" | cut -f1)
            echo "Files generated: $FILE_COUNT"
            echo "Total size: $TOTAL_SIZE"
            echo "Target repo: Kimeiga/japanese-dict-${{ matrix.shard-type }}"
          else
            echo "‚ùå Build failed - no output directory"
          fi

